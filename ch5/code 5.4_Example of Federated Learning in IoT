#Copyright@Zhenhui Yuan, 2025

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt


class IoTSensorModel(nn.Module):
    def __init__(self, input_size=5, output_size=1):
        super().__init__()
        self.network = nn.Sequential(
            nn.Linear(input_size, 16),
            nn.ReLU(),
            nn.Linear(16, 8),
            nn.ReLU(),
            nn.Linear(8, output_size)
        )

    def forward(self, x):
        return self.network(x)


class FederatedLearningSimulator:
    def __init__(self, num_devices=5, packet_loss_rate=0.0):
        self.packet_loss_rate = packet_loss_rate
        self.devices = [
            {
                'id': i,
                'data': self._generate_device_data(),
                'model': IoTSensorModel()
            } for i in range(num_devices)
        ]

        self.global_model = IoTSensorModel()
        self.global_performance_history = []

    def _generate_device_data(self):
        num_samples = 100
        input_features = 5
        X = np.random.randn(num_samples, input_features)

        noise_scale = np.random.uniform(0.1, 0.5)
        y = (X[:, 0] * 0.5 +
             X[:, 1] * 0.3 +
             X[:, 2] * 0.2 +
             np.random.normal(0, noise_scale, num_samples)).reshape(-1, 1)

        return {
            'X': torch.FloatTensor(X),
            'y': torch.FloatTensor(y)
        }

    def local_training(self, device):
        model = device['model']
        data = device['data']

        criterion = nn.MSELoss()
        optimizer = optim.Adam(model.parameters(), lr=0.01)

        for _ in range(5):
            optimizer.zero_grad()
            outputs = model(data['X'])
            loss = criterion(outputs, data['y'])
            loss.backward()
            optimizer.step()

        return {
            'device_id': device['id'],
            'state_dict': model.state_dict(),
            'num_samples': len(data['X'])
        }

    def federated_averaging(self, local_updates):
        # Simulate packet loss
        filtered_updates = [
            update for update in local_updates
            if np.random.random() >= self.packet_loss_rate
        ]

        if not filtered_updates:
            print("All updates lost due to packet loss!")
            return

        global_state = self.global_model.state_dict()
        total_samples = sum(update['num_samples'] for update in filtered_updates)

        for key in global_state.keys():
            global_state[key] = torch.zeros_like(global_state[key])

        for update in filtered_updates:
            weight = update['num_samples'] / total_samples
            for key in global_state.keys():
                global_state[key] += weight * update['state_dict'][key]

        self.global_model.load_state_dict(global_state)

    def evaluate_global_model(self):
        all_X = torch.cat([device['data']['X'] for device in self.devices])
        all_y = torch.cat([device['data']['y'] for device in self.devices])

        with torch.no_grad():
            predictions = self.global_model(all_X)
            mse = nn.MSELoss()(predictions, all_y)
            r2 = 1 - (torch.sum((predictions - all_y) ** 2) / torch.sum((all_y - all_y.mean()) ** 2))
            return mse.item(), r2.item()

    def run_federated_learning(self, num_rounds=10):
        performance_history = []

        for round in range(num_rounds):
            local_updates = []
            for device in self.devices:
                update = self.local_training(device)
                local_updates.append(update)

            self.federated_averaging(local_updates)

            mse, r2 = self.evaluate_global_model()
            performance_history.append({
                'round': round,
                'mse': mse,
                'r2': r2
            })

            print(f"Round {round + 1}: MSE = {mse:.4f}, R2 = {r2:.4f}")

        return performance_history


def plot_performance_analysis():
    # Plot 1: Performance vs Rounds
    plt.figure(figsize=(15, 5))

    plt.subplot(1, 3, 1)
    rounds_performance = []
    for num_rounds in [5, 10, 15, 20]:
        simulator = FederatedLearningSimulator(num_devices=5)
        performance = simulator.run_federated_learning(num_rounds)
        rounds_performance.append({
            'rounds': num_rounds,
            'final_r2': performance[-1]['r2']
        })

    plt.title('Model Accuracy vs Rounds')
    plt.bar([str(p['rounds']) for p in rounds_performance],
            [p['final_r2'] for p in rounds_performance])
    plt.xlabel('Number of Rounds')
    plt.ylabel('Final R2 Score')

    # Plot 2: Performance vs Number of Nodes
    plt.subplot(1, 3, 2)
    nodes_performance = []
    for num_devices in [3, 5, 10, 15]:
        simulator = FederatedLearningSimulator(num_devices=num_devices)
        performance = simulator.run_federated_learning(num_rounds=10)
        nodes_performance.append({
            'nodes': num_devices,
            'final_r2': performance[-1]['r2']
        })

    plt.title('Model Accuracy vs Number of Nodes')
    plt.bar([str(p['nodes']) for p in nodes_performance],
            [p['final_r2'] for p in nodes_performance])
    plt.xlabel('Number of Nodes')
    plt.ylabel('Final R2 Score')

    # Plot 3: Convergence Time vs Number of Nodes
    plt.subplot(1, 3, 3)
    convergence_times = []
    for num_devices in [3, 5, 10, 15]:
        import time
        start_time = time.time()
        simulator = FederatedLearningSimulator(num_devices=num_devices)
        simulator.run_federated_learning(num_rounds=10)
        convergence_time = time.time() - start_time
        convergence_times.append({
            'nodes': num_devices,
            'time': convergence_time
        })

    plt.title('Convergence Time vs Number of Nodes')
    plt.bar([str(p['nodes']) for p in convergence_times],
            [p['time'] for p in convergence_times])
    plt.xlabel('Number of Nodes')
    plt.ylabel('Convergence Time (seconds)')

    plt.tight_layout()
    plt.show()


# Run the performance analysis
if __name__ == "__main__":
    np.random.seed(42)
    torch.manual_seed(42)

    plot_performance_analysis()
